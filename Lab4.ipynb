{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq6eeI29r8qXQwQhbDVjVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullahAlTalaq/About-Me/blob/main/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Abdullah Mohammed Al Talaq\n",
        "#2200001965\n",
        "#lab4"
      ],
      "metadata": {
        "id": "Bt3CEdQFuwab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#I used only pandas and word2vec.. but i upload the rest of the librarys in case if need it"
      ],
      "metadata": {
        "id": "CSyzm0youylF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LlDz1CAmody"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import gensim\n",
        "import re\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lodaing data\n",
        "df = pd.read_csv(\"/content/simpsons_dataset.csv\")"
      ],
      "metadata": {
        "id": "uMmh0mS2nC5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cheak the name of features\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DycD15S_o2f6",
        "outputId": "d2505cf7-3ab0-4b72-f5f6-6ef98551eb22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['raw_character_text', 'spoken_words'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fill null values so i can train the model\n",
        "df['spoken_words'] = df['spoken_words'].fillna(\"\")"
      ],
      "metadata": {
        "id": "EWVKfmTzpURH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the text column spoken_words.\n",
        "sentences = [text.split() for text in df['spoken_words']]"
      ],
      "metadata": {
        "id": "VlAplpQNngop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the Word2Vec model on tokenized text data spoken_words.\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, sg=0, workers=4)\n"
      ],
      "metadata": {
        "id": "l7TMjo1rpbkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vector_size: This parameter specifies the dimensionality of the word vectors (word embeddings) that the model will produce. A higher value like 100 or 300 means that the word vectors will have more dimensions, which can capture more complex relationships between words. However, larger vector sizes require more training data and computational resources.\n",
        "\n",
        "window: The window parameter determines the maximum distance between the current and predicted word within a sentence. It defines the context size for the model. For example, if window is set to 5, the model considers the five words before and five words after the target word as context when learning the word embeddings.\n",
        "\n",
        "min_count: This parameter specifies the minimum number of times a word must appear in the training corpus to be considered for inclusion in the vocabulary. Words that occur less frequently than min_count will be ignored. Setting it to a small value like 1 ensures that even rare words are included, while a higher value like 5 or 10 filters out less common words.\n",
        "\n",
        "sg (Skip-Gram): This is a binary parameter (0 or 1) that determines the training algorithm used by the Word2Vec model. If sg is set to 1, it uses the Skip-Gram model. The Skip-Gram model aims to predict the context words (surrounding words) based on the current word. If sg is set to 0, it uses the Continuous Bag of Words (CBOW) model, which tries to predict the current word based on its context.\n",
        "\n",
        "workers: This parameter specifies the number of CPU cores to use for training the Word2Vec model. A higher value can speed up training by parallelizing the process across multiple cores, which is especially useful when dealing with large datasets.\n",
        "\n",
        "#chatgpt"
      ],
      "metadata": {
        "id": "Rsd74QLNt-k2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topn parameter in the wv.most_similar() method controls the number of most similar words or word vectors to return. It specifies how many of the most similar words you want to retrieve when finding words similar to a given target word. Here's how it works:\n",
        "\n",
        "When you call wv.most_similar() to find similar words to a target word, you pass the topn parameter with an integer value. For example, if you specify topn=5, the method will return a list of the 5 most similar words to the target word, ranked by their similarity scores (cosine similarity or other similarity metric). The higher the similarity score, the more similar the word is to the target word.\n",
        "#chatgpt"
      ],
      "metadata": {
        "id": "mJIKg7_kuZ1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# words similar to \"homer\"\n",
        "similar_to_homer = model.wv.most_similar(\"homer\", topn=5)\n",
        "print(\"Words similar to homer:\")\n",
        "for word, score in similar_to_homer:\n",
        "    print(word, score)\n",
        "\n",
        "# Find words similar to \"marge\"\n",
        "similar_to_marge = model.wv.most_similar(\"Marge\", topn=5)\n",
        "print(\"\\nWords similar to marge:\")\n",
        "for word, score in similar_to_marge:\n",
        "    print(word, score)\n",
        "\n",
        "# Find words similar to \"bart\"\n",
        "similar_to_bart = model.wv.most_similar(\"bart\", topn=5)\n",
        "print(\"\\nWords similar to bart:\")\n",
        "for word, score in similar_to_bart:\n",
        "    print(word, score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Du0kitipkpk",
        "outputId": "720f8751-54ab-4618-abc5-6669c7a07304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to homer:\n",
            "misery 0.7154079079627991\n",
            "hungering 0.7093738317489624\n",
            "pig, 0.6847384572029114\n",
            "gorilla, 0.6809508800506592\n",
            "raccoon. 0.6724455952644348\n",
            "\n",
            "Words similar to marge:\n",
            "Lisa 0.9511016011238098\n",
            "Bart 0.9457570910453796\n",
            "Homer 0.9280368685722351\n",
            "Maggie 0.8521086573600769\n",
            "Mom 0.8509753942489624\n",
            "\n",
            "Words similar to bart:\n",
            "shirt 0.8578076362609863\n",
            "teeth 0.8543229699134827\n",
            "chest 0.8538127541542053\n",
            "horse 0.8530541062355042\n",
            "sky 0.8503484725952148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity between \"moe's\" and \"tavern\"\n",
        "similarity_moes_tavern = model.wv.similarity(\"Moe's\", \"tavern\")\n",
        "print(\"Cosine similarity between 'moe's' and 'tavern':\", similarity_moes_tavern)\n",
        "\n",
        "#  similarity between \"maggie\" and \"baby\"\n",
        "similarity_maggie_baby = model.wv.similarity(\"Maggie\", \"baby\")\n",
        "print(\"Cosine similarity between 'maggie' and 'baby':\", similarity_maggie_baby)\n",
        "\n",
        "#  similarity between \"bart\" and \"nelson\"\n",
        "similarity_bart_nelson = model.wv.similarity(\"Bart\", \"Nelson\")\n",
        "print(\"Cosine similarity between 'bart' and 'nelson':\", similarity_bart_nelson)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irnp4jqeqhCw",
        "outputId": "d8cf5452-6fdc-485b-9b4f-d19db775373d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'moe's' and 'tavern': 0.7826678\n",
            "Cosine similarity between 'maggie' and 'baby': 0.7712844\n",
            "Cosine similarity between 'bart' and 'nelson': 0.4708528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List 1: 'jimbo', 'milhouse', 'kearney'\n",
        "list1 = ['Jimbo', 'Milhouse', 'Kearney']\n",
        "odd_one_out1 = model.wv.doesnt_match(list1)\n",
        "print(\"Word that does not belong in list1:\", odd_one_out1)\n",
        "\n",
        "# List 2: \"nelson\", \"bart\", \"milhouse\"\n",
        "list2 = [\"nelson\", \"bart\", \"milhouse\"]\n",
        "odd_one_out2 = model.wv.doesnt_match(list2)\n",
        "print(\"Word that does not belong in list2:\", odd_one_out2)\n",
        "\n",
        "# List 3: 'homer', 'patty', 'selma'\n",
        "list3 = ['homer', 'patty', 'selma']\n",
        "odd_one_out3 = model.wv.doesnt_match(list3)\n",
        "print(\"Word that does not belong in list3:\", odd_one_out3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s76fEMFTrez9",
        "outputId": "c933f25e-eea3-4c5f-abff-7f595bd8d73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:vectors for words {'nelson', 'milhouse'} are not present in the model, ignoring these words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word that does not belong in list1: Milhouse\n",
            "Word that does not belong in list2: bart\n",
            "Word that does not belong in list3: homer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_to_woman_as_homer_to_marge = model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"Marge\"], topn=3)\n",
        "print(\"Word that is to 'woman' as 'homer' is to 'marge':\", similar_to_woman_as_homer_to_marge[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNJrnzX-sHjD",
        "outputId": "e56fd14d-5630-438d-de3e-ea819ecbcc19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word that is to 'woman' as 'homer' is to 'marge': pig,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_to_woman_as_bart_to_man = model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)\n",
        "print(\"Word that is to 'woman' as 'bart' is to 'man':\", similar_to_woman_as_bart_to_man[0][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlcJ16Sgsdxz",
        "outputId": "aeccbf15-7ca4-44f4-fc82-7d794596da2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word that is to 'woman' as 'bart' is to 'man': chick\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note: I uesd chatgpt\n"
      ],
      "metadata": {
        "id": "Dm4xQFMbuh-d"
      }
    }
  ]
}